Reinforcement Learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. It differs from supervised learning in that labelled input/output pairs are not needed, and sub-optimal actions need not be explicitly corrected.

The basic RL framework consists of an agent, environment, states, actions, and rewards. The agent learns to achieve a goal in an uncertain, potentially complex environment. The agent uses trial and error to come up with a solution to the problem. To get the machine to do what the programmer wants, the artificial intelligence gets either rewards or penalties for the actions it performs.

Key algorithms in RL include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and Actor-Critic methods. Applications range from game playing (like AlphaGo) to robotics, autonomous vehicles, and recommendation systems.